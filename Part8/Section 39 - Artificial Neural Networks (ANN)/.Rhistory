setwd("~/Documentos/UDEMY/ML A-Z/Part8/Section 39 - Artificial Neural Networks (ANN)")
df=read.csv('Churn_Modelling.csv')
View(df)
View(df)
df=df[,4:15]
df=df[,4:14]
View(df)
View(df)
View(df)
View(df)
df$Geography=factor(df$Geography,
levels=c("France", "Spain", "Germany"),
labels=c(1,2,3))
df$Gender=factor(df$Gender,
levels=c("Female", "Male"),
labels=c(0,1))
#Dividir los datos en entrenamiento y conjunto de test
#install.packages("caTools")
library(caTools)
set.seed(123)
training_set[,1:11]=scale(training_set[,1:11])
#Dividir los datos en entrenamiento y conjunto de test
#install.packages("caTools")
library(caTools)
set.seed(123)
sample=sample.split(df$Exited, SplitRatio = 0.8)
training_set=subset(df, sample==TRUE)
testing_set=subset(df, sample==FALSE)
#Escalado de Valores
training_set[,1:11]=scale(training_set[,1:11])
View(training_set)
View(training_set)
df$Geography=as.numeric(factor(df$Geography,
df$Gender=as.numeric(factor(df$Gender,
library(caTools)
#Dividir los datos en entrenamiento y conjunto de test
#install.packages("caTools")
library(caTools)
set.seed(123)
sample=sample.split(df$Exited, SplitRatio = 0.8)
training_set=subset(df, sample==TRUE)
testing_set=subset(df, sample==FALSE)
#Escalado de Valores
training_set[,1:11]=scale(training_set[,1:11])
View(df)
df$Geography=as.numeric(factor(df$Geography,
levels=c("France", "Spain", "Germany"),
labels=c(1,2,3)))
df$Gender=as.numeric(factor(df$Gender,
levels=c("Female", "Male"),
labels=c(0,1)))
library(caTools)
set.seed(123)
sample=sample.split(df$Exited, SplitRatio = 0.8)
training_set=subset(df, sample==TRUE)
testing_set=subset(df, sample==FALSE)
View(df)
View(df)
df$Geography=as.numeric(factor(df$Geography,
levels=c("France", "Spain", "Germany"),
labels=c(1,2,3)))
df$Geography=factor(df$Geography,
levels=c("France", "Spain", "Germany"),
labels=c(1,2,3))
df=read.csv('Churn_Modelling.csv')
df=df[,4:14]
df$Geography=as.numeric(factor(df$Geography,
levels=c("France", "Spain", "Germany"),
labels=c(1,2,3)))
df$Gender=as.numeric(factor(df$Gender,
levels=c("Female", "Male"),
labels=c(0,1)))
set.seed(123)
sample=sample.split(df$Exited, SplitRatio = 0.8)
training_set=subset(df, sample==TRUE)
testing_set=subset(df, sample==FALSE)
#Escalado de Valores
training_set[,1:10]=scale(training_set[,1:10])
testing_set[,1:10]=scale(testing_set[,1:10])
View(training_set)
View(training_set)
install.packages("h20")
install.packages("h2o")
#-----<Crear Red Neuronal>-----
library("h2o")
h2o.init(ntreads=-1)
h2o.init(nthreads=-1)
classifier=h2o.deeplearning(y="Exited",
training_frame = as.h20(training_set),
activation = "Rectifier",
hidden = c(6,6),
epochs = 100,
train_samples_per_iteration = -2)
classifier=h2o.deeplearning(y="Exited",
training_frame = as.h2o(training_set),
activation = "Rectifier",
hidden = c(6,6),
epochs = 100,
train_samples_per_iteration = -2)
#-----<Crear Modelo de Clasificación>----
#crear prediccion si el resultado esperado es una  probabilidad:
prob_pred=h20.predict(classifier,
newdata = as.h2o(testing_set[,-11]))
#-----<Crear Modelo de Clasificación>----
#crear prediccion si el resultado esperado es una  probabilidad:
prob_pred=h2o.predict(classifier,
newdata = as.h2o(testing_set[,-11]))
y_pred=ifelse(prob_pred>0.5, 1, 0)
y_pred=ifelse(prob_pred>0.5)
#-----<Crear Modelo de Clasificación>----
#crear prediccion si el resultado esperado es una  probabilidad:
prob_pred=h2o.predict(classifier,
newdata = as.h2o(testing_set[,-11]))
y_pred=(prob_pred>0.5)
y_pred=as.vector(y_pred)
#Matriz de confucción para evaluar eficiencia
cm=table(testing_set[,11],
y_pred)
cm
clear
View(classifier)
clr
#Importar Dataset
df=read.csv('Churn_Modelling.csv')
#filtrado de datasets (filas, columnas)
df=df[,4:14]
df$Geography=as.numeric(factor(df$Geography,
levels=c("France", "Spain", "Germany"),
labels=c(1,2,3)))
df$Gender=as.numeric(factor(df$Gender,
levels=c("Female", "Male"),
labels=c(0,1)))
#Dividir los datos en entrenamiento y conjunto de test
#install.packages("caTools")
library(caTools)
set.seed(123)
sample=sample.split(df$Exited, SplitRatio = 0.8)
training_set=subset(df, sample==TRUE)
testing_set=subset(df, sample==FALSE)
#Escalado de Valores
training_set[,1:10]=scale(training_set[,1:10])
testing_set[,1:10]=scale(testing_set[,1:10])
#-----<Crear Red Neuronal>-----
library("h2o")
h2o.init(nthreads=-1)
classifier=h2o.deeplearning(y="Exited",
training_frame = as.h2o(training_set),
activation = "Rectifier",
hidden = c(6,6),
epochs = 100,
train_samples_per_iteration = -2)
#-----<Crear Modelo de Clasificación>----
#crear prediccion si el resultado esperado es una  probabilidad:
prob_pred=h2o.predict(classifier,
newdata = as.h2o(testing_set[,-11]))
y_pred=(prob_pred>0.5)
y_pred=as.vector(y_pred)
#Matriz de confucción para evaluar eficiencia
cm=table(testing_set[,11],
y_pred)
cm
#Cerrar la sesión de H2o
h2o.shutdown()
